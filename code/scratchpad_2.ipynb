{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nConditions on the clusters (Y)_s: \\n\\n1, Every v has its r-nbhd completely contained in EXACTLY one cluster. \\n2. Overlap #define as max no' of clusters that contain a single v, less than beta times the beta'th root of n \\n3. For every element in some ker(~) the r-nbhd of that element is contained in ~ .  \\n4. All the kers are disjoint and yet cover the entire set.\\n\\nInvariants through _a single phase_\\n\\n1. All Ys in a phase disjoint. \\n2. All kerZs in a phase disjoint.\\n3. Z can overlap. \\n4. For every element in some ker(~) the r-nbhd of that element is contained in ~ .  \\n5. The union of all Ys is a subset of the union of all kerZs . \\n6. The ker(Z), Z relationship and the ker(Y), Y relationship are maintained -- as well as the Y_s, kerZ_s relationship mentioned above.\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Conditions on the clusters (Y)_s: \n",
    "\n",
    "1, Every v has its r-nbhd completely contained in EXACTLY one cluster. \n",
    "2. Overlap #define as max no' of clusters that contain a single v, less than beta times the beta'th root of n \n",
    "3. For every element in some ker(~) the r-nbhd of that element is contained in ~ .  \n",
    "4. All the kers are disjoint and yet cover the entire set.\n",
    "\n",
    "Invariants through _a single phase_\n",
    "\n",
    "1. All Ys in a phase disjoint. \n",
    "2. All kerZs in a phase disjoint.\n",
    "3. Z can overlap. \n",
    "4. For every element in some ker(~) the r-nbhd of that element is contained in ~ .  \n",
    "5. The union of all Ys is a subset of the union of all kerZs . \n",
    "6. The ker(Z), Z relationship and the ker(Y), Y relationship are maintained -- as well as the Y_s, kerZ_s relationship mentioned above.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('./lib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import plotly.graph_objects as go \n",
    "from lib.graphfig import * \n",
    "from lib.bfs import * \n",
    "from lib.even_shiloach import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def functional_cluster_gen(R:set[int],U:set[int],v:int,Y_s:set[set[int]],G:nx.Graph,r:int,beta:int|float):\n",
    "    print(\"0\") \n",
    "    n = len(G.nodes)\n",
    "    print(\"1\")\n",
    "    if len(Y_s) == 0:\n",
    "        G_notin_Y = G.copy()\n",
    "    else:\n",
    "        G_notin_Y = nx.induced_subgraph(G,set(G.nodes)-set.union(*Y_s))\n",
    "    print(\"2\")\n",
    "    ker_z = set([v,])\n",
    "    T_z = BFSAlgo(G,ker_z,r)\n",
    "    print(\"3\")\n",
    "    z = set(T_z.bfs_graph.nodes)\n",
    "    # try:\n",
    "    for v_z in z:  \n",
    "        assert T_z.bfs_graph.nodes[v_z]['level'] <= r \n",
    "    print(\"4\")\n",
    "    # except AssertionError: \n",
    "    #     print(\"Assertion Error\")\n",
    "    #     print(T_z.bfs_graph.nodes[v_z])\n",
    "    #     print(r)\n",
    "    #     print(z)\n",
    "    #     print(T_z.bfs_graph.nodes)\n",
    "    #     print(T_z.bfs_graph.edges)\n",
    "    #     print(T_z.bfs_graph.nodes[v_z])\n",
    "    #     print(T_z.bfs_graph.nodes[v_z]['level'])\n",
    "    #     print(T_z.bfs_graph.nodes[v_z]['level'] <= r)\n",
    "        # yield T_z\n",
    "\n",
    "    cluster_iters = 0\n",
    "    while True: \n",
    "        print(\"L1\")\n",
    "        ker_y, y = ker_z.copy(), z.copy()\n",
    "        T_z = BFSAlgo(G_notin_Y,y,2*r)\n",
    "        print(\"L2\")\n",
    "        z = set(T_z.bfs_graph.nodes)\n",
    "        ker_z = set([v for v in U.intersection(z) if  T_z.bfs_graph.nodes[v]['level']  <= r ]) \n",
    "        print(\"L3\")\n",
    "        \n",
    "        n_root_beta = n**(1/beta) \n",
    "        lenR_root_beta = len(R)**(1/beta)\n",
    "\n",
    "        A1 = len(z)\n",
    "        A2 = n_root_beta*len(y) \n",
    "        B1 = len(ker_z) \n",
    "        B2 = len(ker_y)*lenR_root_beta\n",
    "        C1 = sum(dict(G.degree(z)).values()) \n",
    "        C2 = sum(dict(G.degree(y)).values())*n_root_beta \n",
    "\n",
    "        print(\"L3\")\n",
    "        \n",
    "        print(f\"Cluster Iteration {cluster_iters}:\")\n",
    "        print(f\"len(z) = {A1}\")\n",
    "        print(f\"len(y) = {len(y)}\") \n",
    "        print(f\"A1 = {round(A1,2)}, A2 = {round(A2,2)}, B1 = {round(B1,2)}, B2 = {round(B2,2)}, C1 = {round(C1,2)}, C2 = {round(C2,2)}\\n\\n\")\n",
    "        # yield None \n",
    "        if(A1 <= A2 and B1 <= B2 and C1 <= C2):\n",
    "            # yield True \n",
    "            break \n",
    "        cluster_iters += 1\n",
    "    return (ker_y, y, ker_z, z)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for p_search in reversed(range(1,31)):\n",
    "    \n",
    "    base_graph =  nx.fast_gnp_random_graph(10000,p_search*1e-4)\n",
    "    try:\n",
    "        assert nx.is_connected(base_graph)\n",
    "    except AssertionError:\n",
    "        print(p_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connected_gnp_graph(n, lower_bound_n, p): \n",
    "    pre_base_graph =  nx.fast_gnp_random_graph(n,p)\n",
    "    cc_nodes_lst = list(nx.connected_components(pre_base_graph))\n",
    "    cc_lens_lst = [len(i) for i in cc_nodes_lst]\n",
    "    idx = cc_lens_lst.index(max(cc_lens_lst)) \n",
    "    base_graph = nx.induced_subgraph(pre_base_graph,cc_nodes_lst[idx]).copy()\n",
    "    try:\n",
    "        assert len(base_graph.nodes) > lower_bound_n\n",
    "    except AssertionError:\n",
    "        print(len(base_graph.nodes)) \n",
    "        print([len(i) for i in nx.connected_components(pre_base_graph)])\n",
    "        raise AssertionError\n",
    "\n",
    "    return base_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3814]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(i) for i in list(nx.connected_components(base_graph))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(100)):\n",
    "    base_graph = get_connected_gnp_graph(20000,5000,0.00006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6134\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "L1\n",
      "L2\n",
      "L3\n",
      "L3\n",
      "Cluster Iteration 0:\n",
      "len(z) = 155\n",
      "len(y) = 17\n",
      "A1 = 155, A2 = 97.27, B1 = 59, B2 = 5.72, C1 = 357, C2 = 223.16\n",
      "\n",
      "\n",
      "L1\n",
      "L2\n",
      "L3\n",
      "L3\n",
      "Cluster Iteration 1:\n",
      "len(z) = 847\n",
      "len(y) = 155\n",
      "A1 = 847, A2 = 886.91, B1 = 393, B2 = 337.6, C1 = 1866, C2 = 2042.76\n",
      "\n",
      "\n",
      "L1\n",
      "L2\n",
      "L3\n",
      "L3\n",
      "Cluster Iteration 2:\n",
      "len(z) = 2864\n",
      "len(y) = 847\n",
      "A1 = 2864, A2 = 4846.54, B1 = 1668, B2 = 2248.75, C1 = 6152, C2 = 10677.27\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "R = set(base_graph.nodes)\n",
    "U = R.copy()\n",
    "v = random.choice(list(base_graph.nodes))\n",
    "Y_s = []\n",
    "G = base_graph\n",
    "r = 4\n",
    "beta = 5\n",
    "print(len(base_graph.nodes))\n",
    "out = functional_cluster_gen(R,U,v,Y_s,G,r,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "L1\n",
      "L2\n",
      "L3\n",
      "L3\n",
      "Cluster Iteration 0:\n",
      "len(z) = 347\n",
      "len(y) = 13\n",
      "A1 = 347, A2 = 136617.0, B1 = 79, B2 = 10509.0, C1 = 1183, C2 = 472905.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "ker_y, y, ker_z, z = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
